{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# import soundfile as sf\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "# processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "# ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n",
    "# generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription = processor.batch_decode(generated_ids)\n",
    "# transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "\n",
    "# SAMPLE_DATA_ROOT = './audio_samples'\n",
    "\n",
    "# for i in range(10):\n",
    "#     data = ds[i][\"audio\"]['array']\n",
    "#     rate = int(ds[i][\"audio\"]['sampling_rate'])\n",
    "#     filename = os.path.join(SAMPLE_DATA_ROOT, f'sample_{i}.flac')\n",
    "#     sf.write(filename, data, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_waveform, rate_of_sample = torchaudio.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def initialize_model_processor(model_name: str,\n",
    "                               processor_name: str) -> Tuple[Speech2TextForConditionalGeneration, Speech2TextProcessor]:\n",
    "    model = Speech2TextForConditionalGeneration.from_pretrained(model_name)\n",
    "    processor = Speech2TextProcessor.from_pretrained(processor_name)\n",
    "    return (model, processor)\n",
    "\n",
    "\n",
    "def transcript_file(data: torch.Tensor,\n",
    "                    sampling_rate: int,\n",
    "                    model: Speech2TextForConditionalGeneration,\n",
    "                    processor: Speech2TextProcessor) -> List[str]:\n",
    "\n",
    "    model_input = processor(data,\n",
    "                            sampling_rate=sampling_rate,\n",
    "                            return_tensors=\"pt\")\n",
    "    model_output = model.generate(model_input[\"input_features\"],\n",
    "                                  attention_mask=model_input[\"attention_mask\"])\n",
    "    transcription = processor.batch_decode(model_output)\n",
    "\n",
    "    return transcription\n",
    "\n",
    "S2T_MODEL = model_name = \"facebook/s2t-small-librispeech-asr\"\n",
    "S2T_PROCESSOR = processor_name = \"facebook/s2t-small-librispeech-asr\"\n",
    "\n",
    "(model, processor) = initialize_model_processor(model_name=S2T_MODEL,\n",
    "                                                processor_name=S2T_PROCESSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA_ROOT = './audio_samples'\n",
    "\n",
    "filename = os.path.join(SAMPLE_DATA_ROOT, 'sample_5.flac')\n",
    "data, sampling_rate = torchaudio.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it is obviously unnecessary for us to point out how luminous these criticisms are how delicate in expression']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape([-1])\n",
    "\n",
    "transcript_file(data=data,\n",
    "                sampling_rate=sampling_rate,\n",
    "                model=model,\n",
    "                processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d75acb95588923971fcdc664c43731cfc2e28c87b62b6583e0e9b4352c0ae9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
